<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fressanlage</title>
    <script src="https://docs.opencv.org/4.5.0/opencv.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        #warning { font-size: 24px; font-weight: bold; color: red; display: none; }
        #chartCanvas { margin-top: 20px; width: 400px; height: 200px; }
    </style>
</head>
<body>
    <h1>Fressanlage</h1>
    <p id="warning">Mach den Mund zu!</p>
    <canvas id="chartCanvas"></canvas>

    <script>
        let openMouthTime = 0, closedMouthTime = 0;
        let lastState = "closed";
        let lastChangeTime = Date.now();

        async function setupCamera() {
            const video = document.createElement("video");
            video.setAttribute("autoplay", "");
            video.setAttribute("playsinline", "");
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            await new Promise(resolve => video.onloadedmetadata = resolve);
            return video;
        }

        async function detectMouth() {
            const video = await setupCamera();
            const cap = new cv.VideoCapture(video);
            const faceCascade = new cv.CascadeClassifier();
            
            // Lade das vortrainierte Haarcascades Modell für Gesichtserkennung
            await new Promise(resolve => cv.FS_createPreloadedFile("/", "haarcascade_frontalface_default.xml", 
                "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml", true, false, resolve));

            faceCascade.load("haarcascade_frontalface_default.xml");

            let frame = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
            let gray = new cv.Mat();
            let faces = new cv.RectVector();
            
            async function processFrame() {
                cap.read(frame);
                cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);
                
                // Gesichtserkennung
                faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);
                
                let mouthOpen = false;
                for (let i = 0; i < faces.size(); i++) {
                    let face = faces.get(i);
                    let mouthRegion = gray.roi(new cv.Rect(face.x, face.y + face.height / 2, face.width, face.height / 2));

                    // Berechne die durchschnittliche Helligkeit des unteren Gesichtsbereichs
                    let mean = cv.mean(mouthRegion);
                    mouthOpen = mean[0] > 120; // Wenn der Bereich zu hell ist, könnte der Mund offen sein

                    mouthRegion.delete();
                }

                // Zeitmessung für Mundstatus
                let currentTime = Date.now();
                if (mouthOpen && lastState === "closed") {
                    closedMouthTime += (currentTime - lastChangeTime) / 1000;
                    lastState = "open";
                    lastChangeTime = currentTime;
                    document.getElementById("warning").style.display = "block";
                } else if (!mouthOpen && lastState === "open") {
                    openMouthTime += (currentTime - lastChangeTime) / 1000;
                    lastState = "closed";
                    lastChangeTime = currentTime;
                    document.getElementById("warning").style.display = "none";
                }

                updateChart();
                requestAnimationFrame(processFrame);
            }

            processFrame();
        }

        function updateChart() {
            if (!window.myChart) {
                const ctx = document.getElementById('chartCanvas').getContext('2d');
                window.myChart = new Chart(ctx, {
                    type: 'bar',
                    data: { labels: ['Mund geschlossen', 'Mund offen'], datasets: [{ label: 'Zeit (Sekunden)', data: [closedMouthTime, openMouthTime], backgroundColor: ['blue', 'red'] }] },
                    options: { responsive: false, scales: { y: { beginAtZero: true } } }
                });
            } else {
                window.myChart.data.datasets[0].data = [closedMouthTime, openMouthTime];
                window.myChart.update();
            }
        }

        detectMouth();
    </script>
</body>
</html>
